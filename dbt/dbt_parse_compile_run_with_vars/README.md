## Запуски parse, compile, run с --vars или что делать, если проект поломался

Предположим, в вашем dbt-проекте есть какие-либо изменения, использование параметров при запуске или что-то ещё, что в какой-то момент даёт вам ошибку 

      Unable to do partial parsing because config vars, config profile, or config target have changed

В моей рабочей жизни причиной такого стало использование запусков dbt run с -- vars. Причём в команде может быть несколько подробностей: с какого места запустить модели, запустить с последующими моделями, обновить ли все модели, какие переменные подставить, какую модель исключить...

      dbt run -m models/1_silos/1_normalize/+ --full-refresh --vars '{"limit0": true,  "metadata_name": "metadata_1" }' --exclude "normalize_appsflyer_events_default_in_app_events"

Такое изобилие - это, конечно, хорошо. Но иногда может настать момент ошибки Unable to do partial parsing. Её коварство в том, что после себя она выдает конкретную модель и её проблему. Но чинить там что-то бесполезно - потому что дело никогда не заключается в этой модели. Ошибка - в парсинге и компилировании проекта из-за этих подставляемых переменных. Как же это починить?

Ответ прост: нам помогут последовательные запуски 
- **parse**
- **compile**
- **run**  -

  
**и все с одинаковыми vars** (и при этом желательно run с full-refresh)

Например, в итоге нас интересует команда:

      dbt run -m models/1_silos/1_normalize/+ --full-refresh --vars '{"limit0": true,  "metadata_name": "metadata_1" }'

Но она падает с ошибкой Unable to do partial parsing и выдаёт нам - я так это называю - ложный след. Как только мы видим Unable to do partial parsing - мы обращаемся к parse и compile.

Запускаем  команду parse с интересующими нас в дальнейшем --vars:

      dbt parse --vars '{"limit0": true, "metadata_name": "metadata_1" }'

После неё запускаем compile - и опять вместе с интересующими vars:

      dbt compile --vars '{"limit0": true, "metadata_name": "metadata_1" }'

И после этого уже команду run (с теми же самыми vars):

      dbt run -m models/1_silos/1_normalize/+ --full-refresh --vars '{"limit0": true,  "metadata_name": "metadata_1" }'

И теперь уже dbt не жалуется на ту модель (ложный след), для которой писал ошибку раньше.

**Детали:**

1. насколько я поняла, для команды parse нет особых **подробностей**, она запускается на весь проект,  к ней нельзя добавить никаких особых деталей, например, --exclude.

А вот для команд compile и run сработает, например, и такое:

      dbt compile  --vars '{"limit0": true, "metadata_name": "metadata_1" }' --exclude "normalize_appsflyer_events_default_in_app_events"

2. почему dbt run с **--full-refresh**? потому что при использовании некоторых --vars (в моём случае метадата), состав полей у некоторых моделей может меняться. Поэтому лучше сразу сделать run с полным обновлением, чем пойти ещё по одному ложному следу - когда dbt скажет, что в какой-то модели есть missing columns.

**Важное замечание**: full-refresh хорош на вашем проекте-эксперименте. А на реальных данных клиента так просто full-refresh ни в коем случае запускать нельзя! У вас могут быть инкрементаьные таблицы, данные в которые добавлялись в течение долгого времени. А full-refresh может очистить всё это богатство под корень и залить только самые последние данные, которые у вас пришли из предыдущего шага (например, данные за последние 3 дня). P.S. просто не спрашивайте, откуда я это знаю...

## Если вы в конец запутались

Можно начать с чистого листа. Для этого существует команда 

      dbt clean
      
Перед её использованием проверяем, что записано в dbt_project.yaml в clean-targets:

      clean-targets:         # directories to be removed by `dbt clean`
        - "target"
        - "dbt_packages"

Обычно это target и packages, и это нормально, ничего критического не удалится. Итак, запускаем команду:

      dbt clean

Затем:

      dbt deps

Для верности можно проверить ещё:

      dbt debug

Далее:

      dbt compile 

(его можно со всякими --vars или --exclude и тп)

И затем уже

      dbt run

(можно со всякими подробностями)
